{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape, Permute\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, UpSampling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.merge import Multiply, Concatenate\n",
    "from keras.utils import np_utils\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import array_to_img, img_to_array, load_img, ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.misc import imresize\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from keras_IndicesPooling import MaxPoolingMask2D\n",
    "from Mylayers import MaxPoolingWithArgmax2D, MaxUnpooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../carvana/data/train/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a18496af6a1f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../carvana/data/train/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmask_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"../carvana/data/train_masks//\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../carvana/data/train/'"
     ]
    }
   ],
   "source": [
    "# set the necessary directories\n",
    "data_dir = \"../carvana/data/train/\"\n",
    "mask_dir = \"../carvana/data/train_masks//\"\n",
    "all_images = os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pick which images we will use for testing and which for validation\n",
    "train_images, validation_images = train_test_split(all_images, train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utility function to convert greyscale images to rgb\n",
    "def grey2rgb(img):\n",
    "    new_img = []\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            new_img.append(list(img[i][j])*3)\n",
    "    new_img = np.array(new_img).reshape(img.shape[0], img.shape[1], 3)\n",
    "    return new_img\n",
    "\n",
    "\n",
    "# generator that we will use to read the data from the directory\n",
    "def data_gen_small(data_dir, mask_dir, images, batch_size, dims):\n",
    "        \"\"\"\n",
    "        data_dir: where the actual images are kept\n",
    "        mask_dir: where the actual masks are kept\n",
    "        images: the filenames of the images we want to generate batches from\n",
    "        batch_size: self explanatory\n",
    "        dims: the dimensions in which we want to rescale our images\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            ix = np.random.choice(np.arange(len(images)), batch_size)\n",
    "            imgs = []\n",
    "            labels = []\n",
    "            for i in ix:\n",
    "                # images\n",
    "                original_img = load_img(data_dir + images[i])\n",
    "                resized_img = imresize(original_img, dims+[3])\n",
    "                array_img = img_to_array(resized_img)/255\n",
    "                imgs.append(array_img)\n",
    "                \n",
    "                # masks\n",
    "                original_mask = load_img(mask_dir + images[i].split(\".\")[0] + '_mask.gif')\n",
    "                resized_mask = imresize(original_mask, dims+[3])\n",
    "                array_mask = img_to_array(resized_mask)/255\n",
    "                labels.append(array_mask[:, :, 0])\n",
    "            imgs = np.array(imgs)\n",
    "            labels = np.array(labels)\n",
    "            yield imgs, labels.reshape(-1, dims[0], dims[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example use\n",
    "train_gen = data_gen_small(data_dir, mask_dir, train_images, 5, [256, 256])\n",
    "img, msk = next(train_gen)\n",
    "\n",
    "plt.imshow(img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(grey2rgb(msk[0]), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def CreateSegNet(input_shape, n_labels, kernel=3, pool_size=(2, 2), loss_mode=\"softmax\"):\n",
    "    # encoder\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(64, (kernel, kernel), padding=\"same\")(inputs)\n",
    "    conv_1 = BatchNormalization()(conv_1)\n",
    "    conv_1 = Activation(\"relu\")(conv_1)\n",
    "    conv_2 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_1)\n",
    "    conv_2 = BatchNormalization()(conv_2)\n",
    "    conv_2 = Activation(\"relu\")(conv_2)\n",
    "    \"\"\"\n",
    "    pool_1 = MaxPooling2D(pool_size)(conv_2)\n",
    "    mask_1 = MaxPoolingMask2D(pool_size)(conv_2)\n",
    "    \"\"\"\n",
    "    pool_1, mask_1 = MaxPoolingWithArgmax2D(pool_size)(conv_2)\n",
    "\n",
    "    conv_3 = Convolution2D(128, (kernel, kernel), padding=\"same\")(pool_1)\n",
    "    conv_3 = BatchNormalization()(conv_3)\n",
    "    conv_3 = Activation(\"relu\")(conv_3)\n",
    "    conv_4 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_3)\n",
    "    conv_4 = BatchNormalization()(conv_4)\n",
    "    conv_4 = Activation(\"relu\")(conv_4)\n",
    "    \"\"\"\n",
    "    pool_2 = MaxPooling2D(pool_size)(conv_4)\n",
    "    mask_2 = MaxPoolingMask2D(pool_size)(conv_4)\n",
    "    \"\"\"\n",
    "    pool_2, mask_2 = MaxPoolingWithArgmax2D(pool_size)(conv_4)\n",
    "\n",
    "    conv_5 = Convolution2D(256, (kernel, kernel), padding=\"same\")(pool_2)\n",
    "    conv_5 = BatchNormalization()(conv_5)\n",
    "    conv_5 = Activation(\"relu\")(conv_5)\n",
    "    conv_6 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_5)\n",
    "    conv_6 = BatchNormalization()(conv_6)\n",
    "    conv_6 = Activation(\"relu\")(conv_6)\n",
    "    conv_7 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_6)\n",
    "    conv_7 = BatchNormalization()(conv_7)\n",
    "    conv_7 = Activation(\"relu\")(conv_7)\n",
    "    \"\"\"\n",
    "    pool_3 = MaxPooling2D(pool_size)(conv_7)\n",
    "    mask_3 = MaxPoolingMask2D(pool_size)(conv_7)\n",
    "    \"\"\"\n",
    "    pool_3, mask_3 = MaxPoolingWithArgmax2D(pool_size)(conv_7)\n",
    "\n",
    "    conv_8 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_3)\n",
    "    conv_8 = BatchNormalization()(conv_8)\n",
    "    conv_8 = Activation(\"relu\")(conv_8)\n",
    "    conv_9 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_8)\n",
    "    conv_9 = BatchNormalization()(conv_9)\n",
    "    conv_9 = Activation(\"relu\")(conv_9)\n",
    "    conv_10 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_9)\n",
    "    conv_10 = BatchNormalization()(conv_10)\n",
    "    conv_10 = Activation(\"relu\")(conv_10)\n",
    "    \"\"\"\n",
    "    pool_4 = MaxPooling2D(pool_size)(conv_10)\n",
    "    mask_4 = MaxPoolingMask2D(pool_size)(conv_10)\n",
    "    \"\"\"\n",
    "    pool_4, mask_4 = MaxPoolingWithArgmax2D(pool_size)(conv_10)\n",
    "\n",
    "    conv_11 = Convolution2D(512, (kernel, kernel), padding=\"same\")(pool_4)\n",
    "    conv_11 = BatchNormalization()(conv_11)\n",
    "    conv_11 = Activation(\"relu\")(conv_11)\n",
    "    conv_12 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_11)\n",
    "    conv_12 = BatchNormalization()(conv_12)\n",
    "    conv_12 = Activation(\"relu\")(conv_12)\n",
    "    conv_13 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_12)\n",
    "    conv_13 = BatchNormalization()(conv_13)\n",
    "    conv_13 = Activation(\"relu\")(conv_13)\n",
    "    \"\"\"\n",
    "    pool_5 = MaxPooling2D(pool_size)(conv_13)\n",
    "    mask_5 = MaxPoolingMask2D(pool_size)(conv_13)\n",
    "    \"\"\"\n",
    "    pool_5, mask_5 = MaxPoolingWithArgmax2D(pool_size)(conv_13)\n",
    "    print(\"Build enceder done..\")\n",
    "\n",
    "    # decoder\n",
    "    \"\"\"\n",
    "    upsample_1 = UpSampling2D(pool_size)(pool_5)\n",
    "    unpool_1 = Multiply()([upsample_1, mask_5])\n",
    "    \"\"\"\n",
    "    unpool_1 = MaxUnpooling2D(pool_size)([pool_5, mask_5])\n",
    "\n",
    "    conv_14 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_1)\n",
    "    conv_14 = BatchNormalization()(conv_14)\n",
    "    conv_14 = Activation(\"relu\")(conv_14)\n",
    "    conv_15 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_14)\n",
    "    conv_15 = BatchNormalization()(conv_15)\n",
    "    conv_15 = Activation(\"relu\")(conv_15)\n",
    "    conv_16 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_15)\n",
    "    conv_16 = BatchNormalization()(conv_16)\n",
    "    conv_16 = Activation(\"relu\")(conv_16)\n",
    "    \"\"\"\n",
    "    upsample_2 = UpSampling2D(pool_size)(conv_16)\n",
    "    unpool_2 = Multiply()([upsample_2, mask_4])\n",
    "    \"\"\"\n",
    "    unpool_2 = MaxUnpooling2D(pool_size)([conv_16, mask_4])\n",
    "\n",
    "    conv_17 = Convolution2D(512, (kernel, kernel), padding=\"same\")(unpool_2)\n",
    "    conv_17 = BatchNormalization()(conv_17)\n",
    "    conv_17 = Activation(\"relu\")(conv_17)\n",
    "    conv_18 = Convolution2D(512, (kernel, kernel), padding=\"same\")(conv_17)\n",
    "    conv_18 = BatchNormalization()(conv_18)\n",
    "    conv_18 = Activation(\"relu\")(conv_18)\n",
    "    conv_19 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_18)\n",
    "    conv_19 = BatchNormalization()(conv_19)\n",
    "    conv_19 = Activation(\"relu\")(conv_19)\n",
    "    \"\"\"\n",
    "    upsample_3 = UpSampling2D(pool_size)(conv_19)\n",
    "    unpool_3 = Multiply()([upsample_3, mask_3])\n",
    "    \"\"\"\n",
    "    unpool_3 = MaxUnpooling2D(pool_size)([conv_19, mask_3])\n",
    "\n",
    "    conv_20 = Convolution2D(256, (kernel, kernel), padding=\"same\")(unpool_3)\n",
    "    conv_20 = BatchNormalization()(conv_20)\n",
    "    conv_20 = Activation(\"relu\")(conv_20)\n",
    "    conv_21 = Convolution2D(256, (kernel, kernel), padding=\"same\")(conv_20)\n",
    "    conv_21 = BatchNormalization()(conv_21)\n",
    "    conv_21 = Activation(\"relu\")(conv_21)\n",
    "    conv_22 = Convolution2D(128, (kernel, kernel), padding=\"same\")(conv_21)\n",
    "    conv_22 = BatchNormalization()(conv_22)\n",
    "    conv_22 = Activation(\"relu\")(conv_22)\n",
    "    \"\"\"\n",
    "    upsample_4 = UpSampling2D(pool_size)(conv_22)\n",
    "    unpool_4 = Multiply()([upsample_4, mask_2])\n",
    "    \"\"\"\n",
    "    unpool_4 = MaxUnpooling2D(pool_size)([conv_22, mask_2])\n",
    "\n",
    "    conv_23 = Convolution2D(128, (kernel, kernel), padding=\"same\")(unpool_4)\n",
    "    conv_23 = BatchNormalization()(conv_23)\n",
    "    conv_23 = Activation(\"relu\")(conv_23)\n",
    "    conv_24 = Convolution2D(64, (kernel, kernel), padding=\"same\")(conv_23)\n",
    "    conv_24 = BatchNormalization()(conv_24)\n",
    "    conv_24 = Activation(\"relu\")(conv_24)\n",
    "    \"\"\"\n",
    "    upsample_5 = UpSampling2D(pool_size)(conv_24)\n",
    "    unpool_5 = Multiply()([upsample_5, mask_1])\n",
    "    \"\"\"\n",
    "    unpool_5 = MaxUnpooling2D(pool_size)([conv_24, mask_1])\n",
    "\n",
    "    conv_25 = Convolution2D(64, (kernel, kernel), padding=\"same\")(unpool_5)\n",
    "    conv_25 = BatchNormalization()(conv_25)\n",
    "    conv_25 = Activation(\"relu\")(conv_25)\n",
    "\n",
    "    conv_26 = Convolution2D(n_labels, (1, 1), padding=\"valid\")(conv_25)\n",
    "    conv_26 = BatchNormalization()(conv_26)\n",
    "\n",
    "    #conv_26 = Reshape((input_shape[0] * input_shape[1], n_labels), input_shape=(input_shape[0], input_shape[1], n_labels))(conv_26)\n",
    "    #conv_26 = Permute((2, 1))(conv_26)\n",
    "    outputs = Activation(loss_mode)(conv_26)\n",
    "    print(\"Build decoder done..\")\n",
    "\n",
    "    segnet = Model(inputs=inputs, outputs=outputs, name=\"SegNet\")\n",
    "\n",
    "    return segnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segnet = CreateSegNet((256, 256, 3), 1, 3, (2, 2),loss_mode=\"sigmoid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segnet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "segnet.load_weights(\"../../../kaggle/carvana/SegNet10.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now let's use Tensorflow to write our own dice_coeficcient metric\n",
    "def dice_coef(y_true, y_pred):\n",
    "    smooth = 1e-5\n",
    "    \n",
    "    y_true = tf.round(tf.reshape(y_true, [-1]))\n",
    "    y_pred = tf.round(tf.reshape(y_pred, [-1]))\n",
    "    \n",
    "    isct = tf.reduce_sum(y_true * y_pred)\n",
    "    \n",
    "    return 2 * isct / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = segnet.evaluate_generator(train_gen, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
